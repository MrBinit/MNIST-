{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values to the range [0, 1]\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "# Flatten the images from 28x28 to a 1D array of 784 pixels\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values to the range [0, 1]\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "# Flatten the images from 28x28 to a 1D array of 784 pixels\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_learning_rate(model, X_train, y_train, loss_fn, lr_start=1e-4, lr_end=1.0, num_batches=100):\n",
    "    lr_finder = tf.keras.experimental.CosineDecay(\n",
    "        initial_learning_rate=lr_start,\n",
    "        decay_steps=num_batches,\n",
    "        alpha=lr_end / lr_start\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(lr_start)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=1, batch_size=32, verbose=0)\n",
    "    learning_rate = lr_finder(tf.range(num_batches))\n",
    "    return learning_rate[-1].numpy()  # Return the final learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found learning rate: 0.9997533\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "lr = find_learning_rate(model, X_train, y_train, 'sparse_categorical_crossentropy')\n",
    "print(\"Found learning rate:\", lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 2s 943us/step - loss: 0.4447 - accuracy: 0.8572 - val_loss: 0.2213 - val_accuracy: 0.9304\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 1s 922us/step - loss: 0.2471 - accuracy: 0.9244 - val_loss: 0.1721 - val_accuracy: 0.9467\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 1s 904us/step - loss: 0.2011 - accuracy: 0.9384 - val_loss: 0.1382 - val_accuracy: 0.9571\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 1s 866us/step - loss: 0.1812 - accuracy: 0.9449 - val_loss: 0.1351 - val_accuracy: 0.9603\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 1s 873us/step - loss: 0.1632 - accuracy: 0.9509 - val_loss: 0.1242 - val_accuracy: 0.9641\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 1s 888us/step - loss: 0.1582 - accuracy: 0.9508 - val_loss: 0.1209 - val_accuracy: 0.9642\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 1s 868us/step - loss: 0.1474 - accuracy: 0.9548 - val_loss: 0.1138 - val_accuracy: 0.9668\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 1s 892us/step - loss: 0.1382 - accuracy: 0.9572 - val_loss: 0.1077 - val_accuracy: 0.9690\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 1s 858us/step - loss: 0.1315 - accuracy: 0.9600 - val_loss: 0.1120 - val_accuracy: 0.9666\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1285 - accuracy: 0.9606 - val_loss: 0.1233 - val_accuracy: 0.9628\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1228 - accuracy: 0.9626 - val_loss: 0.1201 - val_accuracy: 0.9682\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 1s 909us/step - loss: 0.1194 - accuracy: 0.9631 - val_loss: 0.1206 - val_accuracy: 0.9663\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 1s 862us/step - loss: 0.1155 - accuracy: 0.9647 - val_loss: 0.1069 - val_accuracy: 0.9703\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 1s 896us/step - loss: 0.1111 - accuracy: 0.9653 - val_loss: 0.1076 - val_accuracy: 0.9708\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 1s 882us/step - loss: 0.1077 - accuracy: 0.9661 - val_loss: 0.1047 - val_accuracy: 0.9702\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 1s 965us/step - loss: 0.1079 - accuracy: 0.9676 - val_loss: 0.1030 - val_accuracy: 0.9724\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 1s 932us/step - loss: 0.1042 - accuracy: 0.9680 - val_loss: 0.1080 - val_accuracy: 0.9718\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 1s 905us/step - loss: 0.1006 - accuracy: 0.9694 - val_loss: 0.1013 - val_accuracy: 0.9727\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 1s 873us/step - loss: 0.1004 - accuracy: 0.9694 - val_loss: 0.1111 - val_accuracy: 0.9721\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 1s 885us/step - loss: 0.1009 - accuracy: 0.9681 - val_loss: 0.1163 - val_accuracy: 0.9696\n"
     ]
    }
   ],
   "source": [
    "optimal_lr = 0.01  # Use the learning rate found from the learning rate finder\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_lr),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 383us/step - loss: 0.1084 - accuracy: 0.9708\n",
      "Test accuracy: 0.97079998254776\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
